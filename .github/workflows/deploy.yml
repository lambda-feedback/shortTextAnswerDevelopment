name: Build, Test and Deploy

on:
  push:
    branches:
      - main
  pull_request:
  workflow_dispatch:

jobs:
  test:
    name: Test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read
      checks: write
      pull-requests: write
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.11"]
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        id: python-setup
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Load cached Poetry installation
        id: poetry-cache
        uses: actions/cache@v4
        with:
          path: ~/.local
          key: poetry-0

      - name: Install and configure Poetry
        if: steps.poetry-cache.outputs.cache-hit != 'true'
        uses: snok/install-poetry@v1
        with:
          virtualenvs-in-project: true

      - name: Load cached venv
        id: dependencies-cache
        uses: actions/cache@v3
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ steps.python-setup.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies
        if: steps.dependencies-cache.outputs.cache-hit != 'true'
        run: |
          poetry install  --no-interaction --no-root

          apt-get update && apt-get install -y --no-install-recommends \
          wget \
          unzip 

          mkdir -p /usr/share/nltk_data/corpora /usr/share/nltk_data/models /usr/share/nltk_data/tokenizers
          mkdir -p /app/evaluation_function/models

          # NLTK data downloads
          wget -O /usr/share/nltk_data/corpora/wordnet.zip https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/wordnet.zip
          wget -O /usr/share/nltk_data/models/word2vec_sample.zip https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/models/word2vec_sample.zip
          wget -O /usr/share/nltk_data/corpora/brown.zip https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/brown.zip
          wget -O /usr/share/nltk_data/corpora/stopwords.zip https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/stopwords.zip
          wget -O /usr/share/nltk_data/tokenizers/punkt.zip https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/tokenizers/punkt.zip
          wget -O /usr/share/nltk_data/tokenizers/punkt_tab.zip https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/tokenizers/punkt_tab.zip

          # Unzip the downloaded NLTK data
          unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/
          unzip /usr/share/nltk_data/models/word2vec_sample.zip -d /usr/share/nltk_data/models/
          unzip /usr/share/nltk_data/corpora/brown.zip -d /usr/share/nltk_data/corpora/
          unzip /usr/share/nltk_data/corpora/stopwords.zip -d /usr/share/nltk_data/corpora/
          unzip /usr/share/nltk_data/tokenizers/punkt.zip -d /usr/share/nltk_data/tokenizers/
          unzip /usr/share/nltk_data/tokenizers/punkt_tab.zip -d /usr/share/nltk_data/tokenizers/

          # Clean up zip files to reduce image size
          rm /usr/share/nltk_data/corpora/*.zip
          rm /usr/share/nltk_data/models/*.zip
          rm /usr/share/nltk_data/tokenizers/*.zip

          mkdir -p ./evaluation_function/models
          wget -O ./evaluation_function/models/Phi-3.5-mini-instruct-Q6_K.gguf https://huggingface.co/bartowski/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct-Q6_K.gguf

      # TODO: add linting / black / flake8
      # - name: Lint with flake8
      #   run: |
      #     source .venv/bin/activate
      #     # stop the build if there are Python syntax errors or undefined names
      #     flake8 ./evaluation_function --count --select=E9,F63,F7,F82 --show-source --statistics
      #     # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
      #     flake8 ./evaluation_function --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Run tests
        if: always()
        run: |
          source .venv/bin/activate
          pytest --junit-xml=./reports/pytest.xml --tb=auto -v

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: ./reports/pytest.xml
          if-no-files-found: warn

  build:
    name: Build Docker Image
    uses: lambda-feedback/evaluation-function-workflows/.github/workflows/build.yml@main
    needs: test
    with:
      build-args: "memory=10240m"
    permissions:
      contents: read
      id-token: write
      packages: write

  deploy:
    name: Deploy to Lambda Feedback
    uses: lambda-feedback/evaluation-function-workflows/.github/workflows/deploy.yml@main
    needs: test
    with:
      template-repository-name: "lambda-feedback/evaluation-function-boilerplate-python"
      build-args: "memory=10240m"
    permissions:
      contents: read
      id-token: write
      packages: write
    secrets:
      aws-key-id: ${{ secrets.LAMBDA_CONTAINER_PIPELINE_AWS_ID }}
      aws-secret-key: ${{ secrets.LAMBDA_CONTAINER_PIPELINE_AWS_SECRET}}
      function-admin-api-key: ${{ secrets.FUNCTION_ADMIN_API_KEY}}
